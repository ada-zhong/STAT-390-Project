### Weekly Report 5: 5/19
_NOTE: These reports will be for my Kaggle progress only, as I am working with the group on MCMF._

#### Progress:
- I tried out MARS, Lasso, Random Forest, XGBoost models
  - MARS gave me the best initial RMSE, so I wanted to continue with that model 
- I bagged my MARS model and was able to achieve an RMSE of about 9.16
- Started doing dimensionality reduction


#### Problem:
- Running MARS models on my laptop took an extremely long time, upwards of a few hours with bagging at times
- When I used my reduced predictor dataframe from naive PCA my RMSE increased significantly
  - I need to figure out a better method of dimensionality reduction


#### Plan:
- Try using Google Colab to decrease runtime for MARS
- Try tuning MARS hyperparameters
- Figure out the best way to reduce the size of my predictor dataframe
- See if I can incorporate or improve upon other models
  - I want to use boosting models, Neural Networks, and/or ensembling 
