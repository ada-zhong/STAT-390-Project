{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2d08f12d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction problems: Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe6ec7",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. This is the template you may use to submit your code and report for the prediction problems on Kaggle.\n",
    "\n",
    "2. You may modify the template if you deem fit, but it should have the information asked below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d691ac",
   "metadata": {},
   "source": [
    "## A.1) Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaaea5",
   "metadata": {},
   "source": [
    "Mention the data cleaning steps taken to prepare your data for developing the model. This may include imputing missing values, dealing with outliers, combining levels of categorical variable(s), etc.\n",
    "\n",
    "- Imputing missing values:\n",
    "    - I imputed missing values with a KNNImputer using n_neighbors=8.\n",
    "    \n",
    "- Scaling values:\n",
    "    - I scaled my data using a Standard Scaler.\n",
    "\n",
    "- Identifying and discarding predictors *(Total number of predictors finally selected to develop model: 26)*:\n",
    "  - I dropped columns that consisted of the same value for every instance.\n",
    "  - I dropped duplicate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfacd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your data preparation code with comments here\n",
    "# The code should begin from reading the train data\n",
    "# The code should end when you obtain the data used to develop the model(s) in (3)\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrix\n",
    "from pyearth import Earth\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, \\\n",
    "roc_curve, auc, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn import impute\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0face903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Split data into X and y\n",
    "y_train = train.y\n",
    "X_train = train.drop(['id', 'y'], axis=1) \n",
    "X_test = test.drop('id', axis=1)\n",
    "\n",
    "# Take log of y due to skew for later prediction\n",
    "y_train_log = np.log(y_train)\n",
    "\n",
    "# Impute with KNNImputer using k=8\n",
    "imputer = impute.KNNImputer(n_neighbors=8, weights=\"uniform\")\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test) \n",
    "\n",
    "# Turn back into pandas df\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed) \n",
    "X_train_imputed.columns = X_train.columns\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed)\n",
    "X_test_imputed.columns=X_test.columns\n",
    "\n",
    "# Scale with Standard Scaler\n",
    "scaler = StandardScaler().fit(X_train_imputed)\n",
    "X_train_scaled = scaler.transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Turn back into pandas df\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "X_train_scaled.columns = X_train.columns\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "X_test_scaled.columns=X_test.columns\n",
    "\n",
    "# Find meaningless cols (with all the same value)\n",
    "same_val_cols = [col for col in X_train_scaled.columns if X_train_scaled[col].nunique() == 1]\n",
    "\n",
    "# Drop meaningless cols\n",
    "X_train_scaled.drop(same_val_cols, axis=1, inplace=True)\n",
    "X_test_scaled.drop(same_val_cols, axis=1, inplace=True)\n",
    "\n",
    "# Drop duplicate cols from train & test\n",
    "X_train_scaled = X_train_scaled.T.drop_duplicates().T\n",
    "X_test_scaled = X_test_scaled.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1608757",
   "metadata": {},
   "source": [
    "## A.2) Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fff41",
   "metadata": {},
   "source": [
    "Mention any major insights you obtained from the data, which you used to develop the model. Please put your code or visualizations here if needed.\n",
    "\n",
    "1. There are 765 anonymized predictors in the dataset, which informed me that feature selection/dimensionality reduction would be necessary.\n",
    "2. 473 features have missing values, with some features having as much as 16% values missing. \n",
    "3. From a .describe(), I found that there were a wide range of magnitudes across the columns.\n",
    "4. 11 columns only had 1 unique value. \n",
    "5. There are also duplicate columns.\n",
    "6. VIF data demonstrated high multicollinearity.\n",
    "7. A correlation matrix demonstrated high pairwise correlations.\n",
    "8. The target variable has a significant right skew.\n",
    "\n",
    "**None of the below code needs to be run to produce the regression predictions. This code is for EDA purposes only!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b842c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5380, 765)\n",
      "Your selected dataframe has 767 columns.\n",
      "There are 473 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x147</th>\n",
       "      <td>863</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x748</th>\n",
       "      <td>863</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x090</th>\n",
       "      <td>763</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x641</th>\n",
       "      <td>763</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x597</th>\n",
       "      <td>759</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x701</th>\n",
       "      <td>759</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x273</th>\n",
       "      <td>741</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x738</th>\n",
       "      <td>741</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x399</th>\n",
       "      <td>707</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x677</th>\n",
       "      <td>707</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing Values  % of Total Values\n",
       "x147             863               16.0\n",
       "x748             863               16.0\n",
       "x090             763               14.2\n",
       "x641             763               14.2\n",
       "x597             759               14.1\n",
       "x701             759               14.1\n",
       "x273             741               13.8\n",
       "x738             741               13.8\n",
       "x399             707               13.1\n",
       "x677             707               13.1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insight 1 - Number of predictors\n",
    "print(X_train.shape)\n",
    "\n",
    "# Insight 2 - Missing Values\n",
    "# Function to calculate missing values by column\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "    \n",
    "missing_values_table(train).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2b505b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.370000e+03</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5.370000e+03</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5.377000e+03</td>\n",
       "      <td>5.377000e+03</td>\n",
       "      <td>5.327000e+03</td>\n",
       "      <td>5.380000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5378.000000</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5.380000e+03</td>\n",
       "      <td>5375.000000</td>\n",
       "      <td>5327.000000</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5327.000000</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>5005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.623269e+10</td>\n",
       "      <td>14205.468080</td>\n",
       "      <td>6.412851</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>2.978719e+09</td>\n",
       "      <td>0.257727</td>\n",
       "      <td>4.663239e+06</td>\n",
       "      <td>1.968919e+06</td>\n",
       "      <td>2.993064e+05</td>\n",
       "      <td>1.402639e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363471</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>1.031942e+13</td>\n",
       "      <td>0.337180</td>\n",
       "      <td>91.147175</td>\n",
       "      <td>1.931784</td>\n",
       "      <td>49.840248</td>\n",
       "      <td>11.524413</td>\n",
       "      <td>92.241702</td>\n",
       "      <td>0.947097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.214063e+10</td>\n",
       "      <td>11869.274255</td>\n",
       "      <td>0.818170</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>1.860480e+09</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>7.584579e+06</td>\n",
       "      <td>1.690079e+06</td>\n",
       "      <td>1.020525e+06</td>\n",
       "      <td>5.513045e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418773</td>\n",
       "      <td>0.118124</td>\n",
       "      <td>2.626909e+13</td>\n",
       "      <td>0.283159</td>\n",
       "      <td>304.977636</td>\n",
       "      <td>2.379576</td>\n",
       "      <td>170.597793</td>\n",
       "      <td>13.131103</td>\n",
       "      <td>92.728317</td>\n",
       "      <td>4.060325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.135681e+09</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.645178e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.945000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.779690e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.105853e+10</td>\n",
       "      <td>5226.627500</td>\n",
       "      <td>5.930000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547443e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.861619e+05</td>\n",
       "      <td>6.638580e+05</td>\n",
       "      <td>8.189500e+03</td>\n",
       "      <td>6.930000e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.913046e+09</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.364125</td>\n",
       "      <td>20.720000</td>\n",
       "      <td>-0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.767335e+10</td>\n",
       "      <td>11152.340000</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>2.138110e+09</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>1.736036e+06</td>\n",
       "      <td>1.514608e+06</td>\n",
       "      <td>3.631900e+04</td>\n",
       "      <td>2.110000e+15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.210000e+11</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.742150</td>\n",
       "      <td>59.970000</td>\n",
       "      <td>-0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.266054e+10</td>\n",
       "      <td>19231.150000</td>\n",
       "      <td>6.860000</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>4.460250e+09</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.082900e+06</td>\n",
       "      <td>2.881438e+06</td>\n",
       "      <td>1.271430e+05</td>\n",
       "      <td>4.402500e+16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499175</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>9.265000e+12</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.204225</td>\n",
       "      <td>135.830000</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.950000e+11</td>\n",
       "      <td>56364.780000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>9.848333e+09</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.763421e+07</td>\n",
       "      <td>7.936897e+06</td>\n",
       "      <td>8.411828e+06</td>\n",
       "      <td>7.190000e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>5.570700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2106.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1165.000000</td>\n",
       "      <td>110.527800</td>\n",
       "      <td>421.200000</td>\n",
       "      <td>53.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x001          x002         x003         x004          x005  \\\n",
       "count  5.370000e+03   5380.000000  5377.000000  5380.000000  5.370000e+03   \n",
       "mean   4.623269e+10  14205.468080     6.412851     0.003794  2.978719e+09   \n",
       "std    5.214063e+10  11869.274255     0.818170     0.012201  1.860480e+09   \n",
       "min    1.135681e+09      3.800000     1.000000     0.000000  5.645178e+08   \n",
       "25%    1.105853e+10   5226.627500     5.930000     0.000300  1.547443e+09   \n",
       "50%    2.767335e+10  11152.340000     6.360000     0.000900  2.138110e+09   \n",
       "75%    6.266054e+10  19231.150000     6.860000     0.002700  4.460250e+09   \n",
       "max    4.950000e+11  56364.780000    11.000000     0.342000  9.848333e+09   \n",
       "\n",
       "              x006          x007          x008          x009          x010  \\\n",
       "count  5380.000000  5.377000e+03  5.377000e+03  5.327000e+03  5.380000e+03   \n",
       "mean      0.257727  4.663239e+06  1.968919e+06  2.993064e+05  1.402639e+17   \n",
       "std       0.178621  7.584579e+06  1.690079e+06  1.020525e+06  5.513045e+17   \n",
       "min       0.000000  4.945000e+02  1.000000e+00  1.000000e+00  8.779690e+05   \n",
       "25%       0.000000  4.861619e+05  6.638580e+05  8.189500e+03  6.930000e+13   \n",
       "50%       0.310000  1.736036e+06  1.514608e+06  3.631900e+04  2.110000e+15   \n",
       "75%       0.400000  6.082900e+06  2.881438e+06  1.271430e+05  4.402500e+16   \n",
       "max       0.500000  6.763421e+07  7.936897e+06  8.411828e+06  7.190000e+18   \n",
       "\n",
       "       ...         x756         x757          x758         x759         x760  \\\n",
       "count  ...  5378.000000  5380.000000  5.380000e+03  5375.000000  5327.000000   \n",
       "mean   ...     0.363471     0.028403  1.031942e+13     0.337180    91.147175   \n",
       "std    ...     0.418773     0.118124  2.626909e+13     0.283159   304.977636   \n",
       "min    ...     0.000000     0.000000  1.000000e+00     0.000000     0.000000   \n",
       "25%    ...     0.080000     0.000200  2.913046e+09     0.070000     3.000000   \n",
       "50%    ...     0.234300     0.001000  4.210000e+11     0.270000    12.000000   \n",
       "75%    ...     0.499175     0.004400  9.265000e+12     0.550000    37.000000   \n",
       "max    ...     5.570700     1.000000  2.000000e+14     1.000000  2106.000000   \n",
       "\n",
       "              x761         x762         x763         x764         x765  \n",
       "count  5380.000000  5327.000000  5380.000000  5377.000000  5005.000000  \n",
       "mean      1.931784    49.840248    11.524413    92.241702     0.947097  \n",
       "std       2.379576   170.597793    13.131103    92.728317     4.060325  \n",
       "min       0.000000     0.000000     0.000000     0.000000    -0.990000  \n",
       "25%       0.000000     2.000000     3.364125    20.720000    -0.620000  \n",
       "50%       1.000000     6.000000     6.742150    59.970000    -0.180000  \n",
       "75%       3.000000    18.000000    14.204225   135.830000     0.670000  \n",
       "max      24.000000  1165.000000   110.527800   421.200000    53.820000  \n",
       "\n",
       "[8 rows x 754 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insight 3 - .describe()\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e2490d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    754\n",
       "True      11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insight 4 - meaningless columns\n",
    "(X_train.nunique() == 1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc93797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# Insight 5 - duplicate columns\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df_transposed = X_train.transpose()\n",
    "\n",
    "# Check for duplicate columns\n",
    "duplicates = df_transposed.duplicated()\n",
    "\n",
    "# Print the # of duplicate columns\n",
    "duplicate_columns = df_transposed[duplicates].index\n",
    "print(len(duplicate_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff9159d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>x696</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>x725</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>x312</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>x393</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>x138</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  VIF\n",
       "611    x696  inf\n",
       "636    x725  inf\n",
       "287    x312  inf\n",
       "357    x393  inf\n",
       "131    x138  inf"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insight 6 - VIF\n",
    "X_train_vif = X_train_scaled.copy()\n",
    "\n",
    "X_train_vif = add_constant(X_train_vif)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_train_vif.columns\n",
    "\n",
    "for i in range(len(X_train_vif.columns)):\n",
    "    vif_data.loc[i,'VIF'] = variance_inflation_factor(X_train_vif.values, i)\n",
    "    \n",
    "vif_data.sort_values(by='VIF', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56804074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 7 - pairwise correlations\n",
    "corr_matrix = X_train.corr()\n",
    "\n",
    "# Find the highly correlated features\n",
    "threshold = 0.99\n",
    "high_corr_pairs = np.where(corr_matrix > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3cc7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Distribution')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insight 8 - distribution of target var\n",
    "figsize=(8, 8)\n",
    "\n",
    "# Histogram of the loss\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.hist(train['y'], bins = 100, edgecolor = 'k')\n",
    "plt.xlabel('Unpaid principal balance lost (%)') \n",
    "plt.ylabel('Number of individuals');\n",
    "plt.title('Loss Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43d8af",
   "metadata": {},
   "source": [
    "## A.3) Feature selection/reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc78b0",
   "metadata": {},
   "source": [
    "Mention the steps for feature selection/reduction. Please put your code or visualizations here if needed.\n",
    "\n",
    "- I developed a MARS model with optimal degree 1 to conduct feature selection.\n",
    "    - I found optimal degree 1 by looping through MARS models with degrees 1 through 5 and finding the model that returned the best negative mean squared error (my scoring metric).\n",
    "- I dropped all the predictors that had feature importances of 0.  \n",
    "- I developed my final model in A.4 based on the remaining 26 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71848346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a MARS model for feature selection\n",
    "mars_model = Earth(max_terms=1000, feature_importance_type='rss', max_degree=1)\n",
    "mars_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the feature importances from the MARS model\n",
    "importances = mars_model.feature_importances_\n",
    "\n",
    "# Get the indices of features with importances > 0\n",
    "idx = list(np.where(importances != 0)[0])\n",
    "\n",
    "# Filter the datasets for the important features\n",
    "X_train_mars = X_train_scaled.iloc[:, idx]\n",
    "X_test_mars = X_test_scaled.iloc[:, idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58e2ad",
   "metadata": {},
   "source": [
    "## A.4) Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72c68",
   "metadata": {},
   "source": [
    "Mention the logical sequence of steps taken to obtain the final model. \n",
    "\n",
    "- Model 1: CatBoostRegressor\n",
    "    - I developed a CatBoostRegressor model using default inputs.\n",
    "- Model 2: Bagged CatBoostRegressor\n",
    "    - I bagged Model 1 using n_estimaors=20 (Code is in Part 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "328ff449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose = False).fit(X_train_mars, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc8bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a bagged CatRegressor model\n",
    "bagged_model = BaggingRegressor(base_estimator=model_cat, \n",
    "                                n_estimators=20, \n",
    "                                random_state=1,\n",
    "                                n_jobs=-1).fit(X_train_mars, y_train_log)\n",
    "\n",
    "# Make predictions using bagged model\n",
    "y_pred = np.exp(bagged_model.predict(X_train_mars))\n",
    "intercept = np.mean(y_train-y_pred)\n",
    "final_pred = np.exp(bagged_model.predict(X_test_mars))+intercept\n",
    "\n",
    "# Create predictions df\n",
    "predictions = pd.DataFrame({\"id\":test.iloc[:, 0], \"y\":final_pred})\n",
    "\n",
    "# Clip the predicted y-values in case they are out of range\n",
    "predictions['y'] = predictions['y'].clip(lower=1, upper=100)\n",
    "\n",
    "# Export the predictions as a csv file for Kaggle submission\n",
    "predictions.to_csv(\"regression_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148744c",
   "metadata": {},
   "source": [
    "## A.5) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef6e03",
   "metadata": {},
   "source": [
    "Please provide details of the models/approaches you attempted but encountered challenges or unfavorable outcomes. If feasible, kindly explain the reasons behind their ineffectiveness or lack of success. Additionally, highlight the significant challenges or issues you encountered during the process.\n",
    "\n",
    "- MARS\n",
    "    - I started with a MARS model. I tuned for the number of degrees and obtained a degree of 1. Just using this model (with the data preprocessing from above) gave me a naive RMSE of about 9.37, which I thought was decent.\n",
    "    - My biggest challenge with using a MARS model and tuning the number of degrees was the computational runtime.\n",
    "    \n",
    "- Bagged MARS\n",
    "    - I bagged the above MARS model with 50 estimators which reduced my variance and thus reduced my RMSE to about 9.1. I thought this was a good start, as my peers had presented more complicated techniques that had similar RMSEs. This was also what motivated my usage of MARS for feature importances.\n",
    "    - I hadn't dropped any features beyond the meaningless and duplicate columns, so I knew I would have to do dimensionality reduction to improve my model below the 8.75 threshold.\n",
    "    \n",
    "- Random Forest, Lasso, XGBoostRegressor\n",
    "    - At points during my process I also used the above models based on my peers' EDA presentations as well as my own knowedge. To tune these models, I used GridSearchCV. However, I also encountered issues with runtime and figuring out how to do feature selection in conjunction with these models. I could have tested out using these models further, but found that CatBoostRegressor was the best.\n",
    "\n",
    "- CatBoostRegressor\n",
    "    - This was the model that produced the best RMSE by far. I used the predictors from MARS feature selection with this regressor. It had a low runtime and produced the best RMSE. I used BaggingRegressor to ensemble 20 CatBoostRegressors to get my final predictions and leaderboard RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7b917",
   "metadata": {},
   "source": [
    "## A.6) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0af5e",
   "metadata": {},
   "source": [
    "* Do you feel that you gain valuable experience, skills, and/or knowledge? If yes, please explain what they were. If no, please explain.\n",
    "    - Yes. I was challenged with the abundance of features as well as how they were all anonymized. This made it so that I had to do more EDA and data preparation to arrive at my final dataset of predictors. I feel that my EDA skills were improved as a result.\n",
    "    - I learned how to conduct dimensionality reduction and consider multiple methods for feature selection. Initially, I had tried doing PCA, but I found that wasn't as effective for my final RMSE as using MARS model feature importances.\n",
    "    - I also learned about different types of machine learning models. Throughout my process, I tried out different regressors such as Lasso, MARS, XGBoost, and CatBoostRegressor as well as different ensembling methods.\n",
    "    - I learned how to keep a clean code file with meaningful comments.\n",
    "    - I learned how to present my work in a presentation and report format.\n",
    "\n",
    "\n",
    "* What are things you liked/disliked about the project and/or work on the project?\n",
    "    - I liked that the project was a prediction problem with a clear goal (to produce a low RMSE), just because our MCMF project did not have clear guidelines and it was difficult to do machine learning with the MCMF dataset. \n",
    "    - That being said, it was difficult to juggle doing both the Kaggle prediction problem and the MCMF project at the same time. Having the EDA presentations for both projects on the same day was stressful. \n",
    "    - It also seemed counterintuitive to do the Kaggle EDA presentations when everyone obtained similar EDA insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f42714",
   "metadata": {},
   "source": [
    "## Please make sure your github repo has all the code and  ensure that your code is capable of reproducing the outcomes you have submitted. It is important to avoid any form of academic misconduct or cheating by using your peer's submission file\n",
    "Note: all my code is also contained within this report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
