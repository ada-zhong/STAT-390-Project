{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7684eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrix\n",
    "from pyearth import Earth\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, \\\n",
    "roc_curve, auc, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn import impute\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97683eb",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f238c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Split data into X and y\n",
    "y_train = train.y\n",
    "X_train = train.drop(['id', 'y'], axis=1) \n",
    "X_test = test.drop('id', axis=1)\n",
    "\n",
    "# Take log of y due to skew for later prediction\n",
    "y_train_log = np.log(y_train)\n",
    "\n",
    "# Impute with KNNImputer using k=8\n",
    "imputer = impute.KNNImputer(n_neighbors=8, weights=\"uniform\")\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test) \n",
    "\n",
    "# Turn back into pandas df\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed) \n",
    "X_train_imputed.columns = X_train.columns\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed)\n",
    "X_test_imputed.columns=X_test.columns\n",
    "\n",
    "# Scale with Standard Scaler\n",
    "scaler = StandardScaler().fit(X_train_imputed)\n",
    "X_train_scaled = scaler.transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Turn back into pandas df\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "X_train_scaled.columns = X_train.columns\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "X_test_scaled.columns=X_test.columns\n",
    "\n",
    "# Find meaningless cols (with all the same value)\n",
    "same_val_cols = [col for col in X_train_scaled.columns if X_train_scaled[col].nunique() == 1]\n",
    "\n",
    "# Drop meaningless cols\n",
    "X_train_scaled.drop(same_val_cols, axis=1, inplace=True)\n",
    "X_test_scaled.drop(same_val_cols, axis=1, inplace=True)\n",
    "\n",
    "# Drop duplicate cols from train & test\n",
    "X_train_scaled = X_train_scaled.T.drop_duplicates().T\n",
    "X_test_scaled = X_test_scaled.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb1fc6",
   "metadata": {},
   "source": [
    "## Feature selection/reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95ae6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a MARS model for feature selection\n",
    "mars_model = Earth(max_terms=1000, feature_importance_type='rss', max_degree=1)\n",
    "mars_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the feature importances from the MARS model\n",
    "importances = mars_model.feature_importances_\n",
    "\n",
    "# Get the indices of features with importances > 0\n",
    "idx = list(np.where(importances != 0)[0])\n",
    "\n",
    "# Filter the datasets for the important features\n",
    "X_train_mars = X_train_scaled.iloc[:, idx]\n",
    "X_test_mars = X_test_scaled.iloc[:, idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c011c0f",
   "metadata": {},
   "source": [
    "## Final model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1cc52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose = False).fit(X_train_mars, y_train_log)\n",
    "\n",
    "# Use a bagged CatRegressor model\n",
    "bagged_model = BaggingRegressor(base_estimator=model_cat, \n",
    "                                n_estimators=20, \n",
    "                                random_state=1,\n",
    "                                n_jobs=-1).fit(X_train_mars, y_train_log)\n",
    "\n",
    "# Make predictions using bagged model\n",
    "y_pred = np.exp(bagged_model.predict(X_train_mars))\n",
    "intercept = np.mean(y_train-y_pred)\n",
    "final_pred = np.exp(bagged_model.predict(X_test_mars))+intercept\n",
    "\n",
    "# Create predictions df\n",
    "predictions = pd.DataFrame({\"id\":test.iloc[:, 0], \"y\":final_pred})\n",
    "\n",
    "# Clip the predicted y-values in case they are out of range\n",
    "predictions['y'] = predictions['y'].clip(lower=1, upper=100)\n",
    "\n",
    "# Export the predictions as a csv file for Kaggle submission\n",
    "predictions.to_csv(\"regression_preds_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
